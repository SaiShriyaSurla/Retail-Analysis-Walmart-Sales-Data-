# -*- coding: utf-8 -*-
"""Retail_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fg2NezMSfrXcQWLOYkT8D8UgNuhPz93G
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


file_path = '/content/Walmart_Store_sales.csv'

# Reading the CSV file into a DataFrame
df = pd.read_csv(file_path)

# Displaying the first few rows of the dataframe
print(df.head())

# Checking the information for the dataframe
print(df.info())

# Converting 'Date' to datetime
df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')


# Checking for missing values
print(df.isnull().sum())

# Handling missing values if any
df.fillna(method='ffill', inplace=True)

"""This output indicates that there are no missing values and the handling method(done above) is not required.

# **Basic Statistical Analysis**

Maximum Sales Store
"""

# Store with maximum sales
max_sales_store = df.groupby('Store')['Weekly_Sales'].sum().idxmax()
print("Store with maximum sales:", max_sales_store)

"""Store with Maximum Standard Deviation and coefficient of mean to standard deviation"""

# Store with maximum standard deviation
store_std = df.groupby('Store')['Weekly_Sales'].std()
max_std_store = store_std.idxmax()
coefficient_of_variation = store_std / df.groupby('Store')['Weekly_Sales'].mean()
print("Store with maximum standard deviation:", max_std_store)
print("Coefficient of mean to standard deviation:", coefficient_of_variation[max_std_store])

"""Quarterly Growth in Q3'2012"""

# Quarterly growth for Q3 2012
q3_2012 = df[(df['Date'] >= '2012-07-01') & (df['Date'] <= '2012-09-30')]
growth_q3 = q3_2012.groupby('Store')['Weekly_Sales'].sum().pct_change()
print("Quarterly growth rate in Q3'2012:", growth_q3)

"""Holiday Analysis"""

# Holidays with higher sales than non-holiday season mean
mean_sales_non_holiday = df[df['Holiday_Flag'] == 0]['Weekly_Sales'].mean()
holidays_higher_sales = df[df['Holiday_Flag'] == 1]
holidays_higher_sales = holidays_higher_sales[holidays_higher_sales['Weekly_Sales'] > mean_sales_non_holiday]
print("Holidays with higher sales:", holidays_higher_sales['Date'].unique())

"""Monthly and Semester View of Sales"""

# Monthly view
monthly_sales = df.set_index('Date').groupby(pd.Grouper(freq='M'))['Weekly_Sales'].sum()
print("Monthly sales:", monthly_sales)

# Semester view
semester_sales = df.set_index('Date').groupby(pd.Grouper(freq='2Q'))['Weekly_Sales'].sum()
print("Semester sales:", semester_sales)

print(df.columns)

"""# Building Statistical Model"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Converting 'Date' to datetime, sorting by this column, and creating 'Day' variable
df['Date'] = pd.to_datetime(df['Date'])
df.sort_values('Date', inplace=True)
df['Day'] = (df['Date'] - df['Date'].min()).dt.days + 1

# Defining features and target variable
X = df[['Day', 'CPI', 'Unemployment', 'Fuel_Price']]
y = df['Weekly_Sales']

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Building and training the Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predicting on the test set and calculate RMSE
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print("RMSE:", rmse)

"""# Implementing other models to compare and find the best ones

Random Forest
"""

from sklearn.ensemble import RandomForestRegressor

# Building and training a Random Forest model
rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train, y_train)

# Predicting on the test set and calculating RMSE for Random Forest
y_pred_rf = rf_model.predict(X_test)
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
print("RMSE for Random Forest:", rmse_rf)

# Comparing RMSE of both models
print("RMSE for Linear Regression:", rmse)

"""Gradient Boosting Regressor"""

from sklearn.ensemble import GradientBoostingRegressor

# Building and training the Gradient Boosting model
gb_model = GradientBoostingRegressor(random_state=42)
gb_model.fit(X_train, y_train)

# Predicting on the test set and calculating RMSE for Gradient Boosting
y_pred_gb = gb_model.predict(X_test)
rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_gb))
print("RMSE for Gradient Boosting:", rmse_gb)

"""Support Vector Regression (SVR)"""

from sklearn.svm import SVR

# Building and training the SVR model
svr_model = SVR(kernel='linear')
svr_model.fit(X_train, y_train)

# Predicting on the test set and calculating RMSE for SVR
y_pred_svr = svr_model.predict(X_test)
rmse_svr = np.sqrt(mean_squared_error(y_test, y_pred_svr))
print("RMSE for SVR:", rmse_svr)

"""Comparing all the models built"""

# Storing RMSE values along with model names in a dictionary
rmse_values = {
    "Linear Regression": rmse,
    "Random Forest": rmse_rf,
    "Gradient Boosting": rmse_gb,
    "SVR": rmse_svr
}

# Print RMSE for each model
for model_name, rmse_value in rmse_values.items():
    print(f"RMSE for {model_name}: {rmse_value}")

# Determine the model with the lowest RMSE and print it
min_rmse_model = min(rmse_values, key=rmse_values.get)
print(f"Best model with lowest RMSE is {min_rmse_model} with an RMSE of {rmse_values[min_rmse_model]}")